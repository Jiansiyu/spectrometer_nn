{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HRS Spectrometer Neutrol network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import math\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Training dataset\n",
    "- Merge Multi dataset\n",
    "- randomize the order of the dataset\n",
    "- [ftp data server](http://localhost/Data/spectro_nn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file ../dataGenerator/result/PRex_DataSet_2239.csv\n",
      "Loading file ../dataGenerator/result/PRex_DataSet_2240.csv\n",
      "Loading file ../dataGenerator/result/PRex_DataSet_2241.csv\n",
      "Loading file ../dataGenerator/result/PRex_DataSet_2244.csv\n",
      "Loading file ../dataGenerator/result/PRex_DataSet_2245.csv\n",
      "Loading file ../dataGenerator/result/PRex_DataSet_2256.csv\n",
      "Loading file ../dataGenerator/result/PRex_DataSet_2257.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "   evtID  CutID  SieveRowID  SieveColID      bpmX      bpmY   focal_x  \\\n0   2239    136           3           5  0.003794 -0.000501 -0.014535   \n1   2239    130           4           4  0.003794 -0.000501 -0.027425   \n2   2239    179           4          11  0.003794 -0.000501 -0.013932   \n3   2239    142           2           6  0.003794 -0.000501 -0.010740   \n4   2239    127           1           4  0.003794 -0.000501 -0.002179   \n\n    focal_y  focal_th  focal_ph  targCalTh  targCalPh  \n0  0.011066  0.000552 -0.001618  -0.000817  -0.010117  \n1  0.008514 -0.006709 -0.009000   0.019571  -0.012569  \n2 -0.014659 -0.006437  0.014969   0.012775   0.014835  \n3  0.003021  0.005594  0.001385  -0.014409  -0.003863  \n4  0.012108  0.006449 -0.004135  -0.021206  -0.012569  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>evtID</th>\n      <th>CutID</th>\n      <th>SieveRowID</th>\n      <th>SieveColID</th>\n      <th>bpmX</th>\n      <th>bpmY</th>\n      <th>focal_x</th>\n      <th>focal_y</th>\n      <th>focal_th</th>\n      <th>focal_ph</th>\n      <th>targCalTh</th>\n      <th>targCalPh</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2239</td>\n      <td>136</td>\n      <td>3</td>\n      <td>5</td>\n      <td>0.003794</td>\n      <td>-0.000501</td>\n      <td>-0.014535</td>\n      <td>0.011066</td>\n      <td>0.000552</td>\n      <td>-0.001618</td>\n      <td>-0.000817</td>\n      <td>-0.010117</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2239</td>\n      <td>130</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0.003794</td>\n      <td>-0.000501</td>\n      <td>-0.027425</td>\n      <td>0.008514</td>\n      <td>-0.006709</td>\n      <td>-0.009000</td>\n      <td>0.019571</td>\n      <td>-0.012569</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2239</td>\n      <td>179</td>\n      <td>4</td>\n      <td>11</td>\n      <td>0.003794</td>\n      <td>-0.000501</td>\n      <td>-0.013932</td>\n      <td>-0.014659</td>\n      <td>-0.006437</td>\n      <td>0.014969</td>\n      <td>0.012775</td>\n      <td>0.014835</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2239</td>\n      <td>142</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0.003794</td>\n      <td>-0.000501</td>\n      <td>-0.010740</td>\n      <td>0.003021</td>\n      <td>0.005594</td>\n      <td>0.001385</td>\n      <td>-0.014409</td>\n      <td>-0.003863</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2239</td>\n      <td>127</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.003794</td>\n      <td>-0.000501</td>\n      <td>-0.002179</td>\n      <td>0.012108</td>\n      <td>0.006449</td>\n      <td>-0.004135</td>\n      <td>-0.021206</td>\n      <td>-0.012569</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [\"../dataGenerator/result/PRex_DataSet_2239.csv\",\n",
    "         \"../dataGenerator/result/PRex_DataSet_2240.csv\",\n",
    "         \"../dataGenerator/result/PRex_DataSet_2241.csv\",\n",
    "         \"../dataGenerator/result/PRex_DataSet_2244.csv\",\n",
    "         \"../dataGenerator/result/PRex_DataSet_2245.csv\",\n",
    "         \"../dataGenerator/result/PRex_DataSet_2256.csv\",\n",
    "         \"../dataGenerator/result/PRex_DataSet_2257.csv\"\n",
    "         ]\n",
    "\n",
    "# large data set with all the features \n",
    "# files = [\"../dataGenerator/result/PRex_DataSet_Full_2239.csv\",\n",
    "#          \"../dataGenerator/result/PRex_DataSet_Full_2240.csv\",\n",
    "#          \"../dataGenerator/result/PRex_DataSet_Full_2241.csv\",\n",
    "#          \"../dataGenerator/result/PRex_DataSet_Full_2244.csv\",\n",
    "#          \"../dataGenerator/result/PRex_DataSet_Full_2245.csv\",\n",
    "#          \"../dataGenerator/result/PRex_DataSet_Full_2256.csv\",\n",
    "#          \"../dataGenerator/result/PRex_DataSet_Full_2257.csv\"\n",
    "#          ]\n",
    "li = []\n",
    "for filename in files:\n",
    "    print(\"Loading file {}\".format(filename))\n",
    "    df = pd.read_csv(filename)\n",
    "    li.append(df)\n",
    "data = pd.concat(li)\n",
    "data.sample(frac=1) # sample the data with fraction 1. rearrange the data in random order\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#print(data[data.evtID.eq(2240)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "x = data[data.evtID.eq(2241)][\"targCalPh\"]\n",
    "y = data[data.evtID.eq(2241)][\"targCalTh\"]\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# New Function Used for Train the X, and Y model seperately"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class OptNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptNet,self).__init__()\n",
    "        #TODO model, need to auto adapt to the training dataset\n",
    "        self.fc1 = nn.Linear(4, 16)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 8)\n",
    "        self.output = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(221493, 12)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerics = ['int16','int32','int64','float16','float32','float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training on the $\\theta_{targ}$\n",
    "### 1. prepare the training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "((177194, 4), (177194, 2), (44299, 4), (44299, 2))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    data.drop(labels=['evtID','SieveRowID','SieveColID','CutID','bpmX','bpmY','targCalTh','targCalPh'], axis=1),\n",
    "    data[['targCalTh','targCalPh']],\n",
    "    test_size=0.2,\n",
    "    random_state=0)\n",
    "\n",
    "train_X.shape,train_y.shape,test_X.shape,test_y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. train the $\\theta_{targ}$ model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_trainTh = torch.tensor(train_X.to_numpy()).float()\n",
    "y_trainTh = torch.tensor(train_y['targCalTh'].to_numpy()).float()\n",
    "X_testTh  = torch.tensor(test_X.to_numpy()).float()\n",
    "y_testTh  = torch.tensor(test_y['targCalTh'].to_numpy()).float()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/newdriver/Storage/HomeDir/Learning/spectrometer_nn/training_nn/venv/lib/python3.9/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/newdriver/Storage/HomeDir/Learning/spectrometer_nn/training_nn/venv/lib/python3.9/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.001007304\n",
      "[1,  4000] loss: 0.000423222\n",
      "[1,  6000] loss: 0.000041730\n",
      "[1,  8000] loss: 0.000047460\n",
      "[1, 10000] loss: 0.000042751\n",
      "[1, 12000] loss: 0.000041424\n",
      "[1, 14000] loss: 0.000043496\n",
      "[1, 16000] loss: 0.000039295\n",
      "[1, 18000] loss: 0.000038548\n",
      "[1, 20000] loss: 0.000030979\n",
      "[1, 22000] loss: 0.000031146\n",
      "[1, 24000] loss: 0.000023805\n",
      "[1, 26000] loss: 0.000024139\n",
      "[1, 28000] loss: 0.000023211\n",
      "[1, 30000] loss: 0.000021039\n",
      "[1, 32000] loss: 0.000022277\n",
      "[1, 34000] loss: 0.000023241\n",
      "[1, 36000] loss: 0.000018491\n",
      "[1, 38000] loss: 0.000018976\n",
      "[1, 40000] loss: 0.000020315\n",
      "[1, 42000] loss: 0.000019514\n",
      "[1, 44000] loss: 0.000018603\n",
      "[1, 46000] loss: 0.000018564\n",
      "[1, 48000] loss: 0.000020371\n",
      "[1, 50000] loss: 0.000017084\n",
      "[1, 52000] loss: 0.000019521\n",
      "[1, 54000] loss: 0.000016991\n",
      "[1, 56000] loss: 0.000019762\n",
      "[1, 58000] loss: 0.000017928\n",
      "[1, 60000] loss: 0.000016807\n",
      "[1, 62000] loss: 0.000017708\n",
      "[1, 64000] loss: 0.000018050\n",
      "[1, 66000] loss: 0.000017458\n",
      "[1, 68000] loss: 0.000018216\n",
      "[1, 70000] loss: 0.000016731\n",
      "[1, 72000] loss: 0.000018635\n",
      "[1, 74000] loss: 0.000016898\n",
      "[1, 76000] loss: 0.000016517\n",
      "[1, 78000] loss: 0.000019199\n",
      "[1, 80000] loss: 0.000017377\n",
      "[1, 82000] loss: 0.000016461\n",
      "[1, 84000] loss: 0.000019584\n",
      "[1, 86000] loss: 0.000016516\n",
      "[1, 88000] loss: 0.000018081\n",
      "[1, 90000] loss: 0.000018185\n",
      "[1, 92000] loss: 0.000016866\n",
      "[1, 94000] loss: 0.000018372\n",
      "[1, 96000] loss: 0.000016657\n",
      "[1, 98000] loss: 0.000017245\n",
      "[1, 100000] loss: 0.000017280\n",
      "[1, 102000] loss: 0.000017743\n",
      "[1, 104000] loss: 0.000013805\n",
      "[1, 106000] loss: 0.000020987\n",
      "[1, 108000] loss: 0.000015761\n",
      "[1, 110000] loss: 0.000017794\n",
      "[1, 112000] loss: 0.000014947\n",
      "[1, 114000] loss: 0.000016667\n",
      "[1, 116000] loss: 0.000015038\n",
      "[1, 118000] loss: 0.000017211\n",
      "[1, 120000] loss: 0.000015937\n",
      "[1, 122000] loss: 0.000015225\n",
      "[1, 124000] loss: 0.000016031\n",
      "[1, 126000] loss: 0.000015829\n",
      "[1, 128000] loss: 0.000015475\n",
      "[1, 130000] loss: 0.000017081\n",
      "[1, 132000] loss: 0.000014990\n",
      "[1, 134000] loss: 0.000017343\n",
      "[1, 136000] loss: 0.000014136\n",
      "[1, 138000] loss: 0.000013908\n",
      "[1, 140000] loss: 0.000016163\n",
      "[1, 142000] loss: 0.000016936\n",
      "[1, 144000] loss: 0.000017021\n",
      "[1, 146000] loss: 0.000015760\n",
      "[1, 148000] loss: 0.000013527\n",
      "[1, 150000] loss: 0.000015983\n",
      "[1, 152000] loss: 0.000016279\n"
     ]
    }
   ],
   "source": [
    "thetaOptnet = OptNet()\n",
    "thetaOptnet.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(thetaOptnet.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1):\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(y_trainTh)):\n",
    "        inputs = X_trainTh[i].to(device)\n",
    "        labels = y_trainTh[i].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = thetaOptnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.9f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finish Training Theta Parameters\")\n",
    "# save the training model\n",
    "theta_model_PATH = './model/Theta_net.pth'\n",
    "torch.save(thetaOptnet.state_dict(), theta_model_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training on the $\\phi_{targ}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. train the $\\phi_{targ}$ model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_trainPh = torch.tensor(train_X.to_numpy()).float()\n",
    "y_trainPh = torch.tensor(train_y['targCalPh'].to_numpy()).float()\n",
    "X_testPh  = torch.tensor(test_X.to_numpy()).float()\n",
    "y_testPh  = torch.tensor(test_y['targCalPh'].to_numpy()).float()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "phiOptnet = OptNet()\n",
    "phiOptnet.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(phiOptnet.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1):\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(y_trainPh)):\n",
    "        inputs = X_trainPh[i].to(device)\n",
    "        labels = y_trainPh[i].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs =  phiOptnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.9f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finish Training Theta Parameters\")\n",
    "# save the training model\n",
    "phi_model_PATH = './model/Phi_net.pth'\n",
    "torch.save(phiOptnet.state_dict(), phi_model_PATH)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the Training model\n",
    "\n",
    "### 1. Seperate Test on the $\\theta$ and $\\phi$ on the test dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "testNet_theta = OptNet()\n",
    "testNet_theta.load_state_dict(torch.load(theta_model_PATH))\n",
    "\n",
    "test_loss = 0\n",
    "mseArr = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(y_testTh)):\n",
    "        positions = X_testTh[i]\n",
    "        labels = y_testTh[i]\n",
    "\n",
    "        outputs = testNet_theta(positions)\n",
    "        loss = criterion(outputs,labels)\n",
    "        test_loss += loss\n",
    "        mseArr.append(loss)\n",
    "print('test_error is :{}   / {}'.format(test_loss,sum(mseArr)/len(mseArr)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testNet_phi = OptNet()\n",
    "testNet_phi.load_state_dict(torch.load(phi_model_PATH))\n",
    "\n",
    "test_loss = 0\n",
    "mseArr = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(y_testPh)):\n",
    "        positions = X_testPh[i]\n",
    "        labels = y_testPh[i]\n",
    "        outputs = testNet_phi(positions)\n",
    "        loss = criterion(outputs,labels)\n",
    "        test_loss += loss\n",
    "        mseArr.append(loss)\n",
    "print('test_error is :{}   / {}'.format(test_loss,sum(mseArr)/len(mseArr)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Seprate the training and test dataset\n",
    "- randomly sperate the dataset into training and test dataset with fixed ratio\n",
    "- auto read the number of features in the dataset, this will be used in the model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['evtID','SieveRowID','SieveColID', 'CutID','bpmX','bpmY','targCalTh','targCalPh'], axis=1),\n",
    "    data['targCalTh'],\n",
    "    test_size=0.2,\n",
    "    random_state=0)\n",
    "train_feature_count = X_train.shape[1]\n",
    "print(\" Number of features in the training : {}  / overall order {}\".format(train_feature_count,math.sqrt(math.sqrt(train_feature_count))-1))\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural Network Training Model\n",
    "- need to preload the data\n",
    "- get the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class OptNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptNet,self).__init__()\n",
    "        #TODO model, need to auto adapt to the training dataset\n",
    "        self.fc1 = nn.Linear(train_feature_count, 4*train_feature_count)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(4*train_feature_count, 4*train_feature_count)\n",
    "        self.fc3 = nn.Linear(4*train_feature_count, 8)\n",
    "        self.output = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "- load the data to the torch tensor\n",
    "- load the GPU Calculation\n",
    "\n",
    "## 1. Seperate the data for TargX and TargY and train the seperate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.to_numpy()).float()\n",
    "y_train = torch.tensor(y_train.to_numpy()).float()\n",
    "X_test  = torch.tensor( X_test.to_numpy()).float()\n",
    "y_test  = torch.tensor( y_test.to_numpy()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = OptNet()\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# training\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(y_train)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = X_train[i].to(device)\n",
    "        labels = y_train[i].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.9f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Finished Training')\n",
    "model_PATH = './model/net.pth'\n",
    "torch.save(net.state_dict(), model_PATH)\n",
    "\n",
    "net = OptNet()\n",
    "net.load_state_dict(torch.load(model_PATH))\n",
    "\n",
    "test_loss = 0\n",
    "mseArr = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(y_test)):\n",
    "        positions = X_test[i]\n",
    "        labels = y_test[i]\n",
    "        outputs = net(positions)\n",
    "        loss = criterion(outputs,labels)\n",
    "        test_loss += loss\n",
    "        mseArr.append(loss)\n",
    "print('test_error is :{}   / {}'.format(test_loss,sum(mseArr)/len(mseArr)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}