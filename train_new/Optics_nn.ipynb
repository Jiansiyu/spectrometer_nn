{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HRS Spectrometer Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import math\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare the data\n",
    "### 1). Load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the file ./data/PRex_DataSet_2239.csv...\n",
      "Loading the file ./data/PRex_DataSet_2240.csv...\n",
      "Loading the file ./data/PRex_DataSet_2241.csv...\n",
      "Loading the file ./data/PRex_DataSet_2244.csv...\n",
      "Loading the file ./data/PRex_DataSet_2245.csv...\n",
      "Loading the file ./data/PRex_DataSet_2256.csv...\n",
      "Loading the file ./data/PRex_DataSet_2257.csv...\n"
     ]
    },
    {
     "data": {
      "text/plain": "   evtID  runID  CutID  SieveRowID  SieveColID      bpmX      bpmY   focal_x  \\\n0      0   2239    136           3           5  0.003794 -0.000501 -0.014535   \n1      1   2239    130           4           4  0.003794 -0.000501 -0.027425   \n2      2   2239    179           4          11  0.003794 -0.000501 -0.013932   \n3      3   2239    142           2           6  0.003794 -0.000501 -0.010740   \n4      4   2239    127           1           4  0.003794 -0.000501 -0.002179   \n\n    focal_y  focal_th  focal_ph  targCalTh  targCalPh  \n0  0.011066  0.000552 -0.001618  -0.000817  -0.010117  \n1  0.008514 -0.006709 -0.009000   0.019571  -0.012569  \n2 -0.014659 -0.006437  0.014969   0.012775   0.014835  \n3  0.003021  0.005594  0.001385  -0.014409  -0.003863  \n4  0.012108  0.006449 -0.004135  -0.021206  -0.012569  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>evtID</th>\n      <th>runID</th>\n      <th>CutID</th>\n      <th>SieveRowID</th>\n      <th>SieveColID</th>\n      <th>bpmX</th>\n      <th>bpmY</th>\n      <th>focal_x</th>\n      <th>focal_y</th>\n      <th>focal_th</th>\n      <th>focal_ph</th>\n      <th>targCalTh</th>\n      <th>targCalPh</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2239</td>\n      <td>136</td>\n      <td>3</td>\n      <td>5</td>\n      <td>0.003794</td>\n      <td>-0.000501</td>\n      <td>-0.014535</td>\n      <td>0.011066</td>\n      <td>0.000552</td>\n      <td>-0.001618</td>\n      <td>-0.000817</td>\n      <td>-0.010117</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2239</td>\n      <td>130</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0.003794</td>\n      <td>-0.000501</td>\n      <td>-0.027425</td>\n      <td>0.008514</td>\n      <td>-0.006709</td>\n      <td>-0.009000</td>\n      <td>0.019571</td>\n      <td>-0.012569</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2239</td>\n      <td>179</td>\n      <td>4</td>\n      <td>11</td>\n      <td>0.003794</td>\n      <td>-0.000501</td>\n      <td>-0.013932</td>\n      <td>-0.014659</td>\n      <td>-0.006437</td>\n      <td>0.014969</td>\n      <td>0.012775</td>\n      <td>0.014835</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2239</td>\n      <td>142</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0.003794</td>\n      <td>-0.000501</td>\n      <td>-0.010740</td>\n      <td>0.003021</td>\n      <td>0.005594</td>\n      <td>0.001385</td>\n      <td>-0.014409</td>\n      <td>-0.003863</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2239</td>\n      <td>127</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.003794</td>\n      <td>-0.000501</td>\n      <td>-0.002179</td>\n      <td>0.012108</td>\n      <td>0.006449</td>\n      <td>-0.004135</td>\n      <td>-0.021206</td>\n      <td>-0.012569</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [\"./data/PRex_DataSet_2239.csv\",\n",
    "         \"./data/PRex_DataSet_2240.csv\",\n",
    "         \"./data/PRex_DataSet_2241.csv\",\n",
    "         \"./data/PRex_DataSet_2244.csv\",\n",
    "         \"./data/PRex_DataSet_2245.csv\",\n",
    "         \"./data/PRex_DataSet_2256.csv\",\n",
    "         \"./data/PRex_DataSet_2257.csv\"\n",
    "         ]\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in files:\n",
    "    print(\"Loading the file {}...\".format(filename))\n",
    "    df = pd.read_csv(filename)\n",
    "    li.append(df)\n",
    "data = pd.concat(li)\n",
    "data.sample(frac=1) # sample the data with fraction 1. rearrange the data in random order\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2). Check the Theoretical Value of $\\theta$ and $\\phi$ on targe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x1080 with 7 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=[15,15])\n",
    "gs = gridspec.GridSpec(nrows=3, ncols=3, height_ratios=[1, 1, 1])\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "ax0.scatter(data[data.runID.eq(2239)][\"targCalPh\"],data[data.runID.eq(2239)][\"targCalTh\"])\n",
    "ax0.set_title('Theoretical Value 2239')\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 1])\n",
    "ax1.scatter(data[data.runID.eq(2240)][\"targCalPh\"],data[data.runID.eq(2240)][\"targCalTh\"])\n",
    "ax1.set_title('Theoretical Value 2240')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "ax2.scatter(data[data.runID.eq(2241)][\"targCalPh\"],data[data.runID.eq(2241)][\"targCalTh\"])\n",
    "ax2.set_title('Theoretical Value 2241')\n",
    "\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax3.scatter(data[data.runID.eq(2244)][\"targCalPh\"],data[data.runID.eq(2244)][\"targCalTh\"])\n",
    "ax3.set_title('Theoretical Value 2244')\n",
    "\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "ax4.scatter(data[data.runID.eq(2245)][\"targCalPh\"],data[data.runID.eq(2245)][\"targCalTh\"])\n",
    "ax4.set_title('Theoretical Value 2245')\n",
    "\n",
    "ax5 = fig.add_subplot(gs[1, 2])\n",
    "ax5.scatter(data[data.runID.eq(2256)][\"targCalPh\"],data[data.runID.eq(2256)][\"targCalTh\"])\n",
    "ax5.set_title('Theoretical Value 2256')\n",
    "\n",
    "ax6 = fig.add_subplot(gs[2, 0])\n",
    "ax6.scatter(data[data.runID.eq(2257)][\"targCalPh\"],data[data.runID.eq(2257)][\"targCalTh\"])\n",
    "ax6.set_title('Theoretical Value 2257')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3). Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import  Dataset, TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    data.drop(labels=['evtID','runID','SieveRowID','SieveColID','CutID','bpmX','bpmY','targCalTh','targCalPh'], axis=1),\n",
    "    data[['targCalTh','targCalPh']],\n",
    "    test_size=0.2,\n",
    "    random_state=0)\n",
    "\n",
    "batchSize = 1\n",
    "\n",
    "train_X_tensor = torch.tensor(train_X.to_numpy()).float()\n",
    "train_yTh_tensor = torch.tensor(train_y['targCalTh'].to_numpy()).float()\n",
    "train_yPh_tensor = torch.tensor(train_y['targCalPh'].to_numpy()).float()\n",
    "\n",
    "test_X_tensor  = torch.tensor(test_X.to_numpy()).float()\n",
    "test_yTh_tensor  = torch.tensor(test_y['targCalTh'].to_numpy()).float()\n",
    "test_yPh_tensor  = torch.tensor(test_y['targCalPh'].to_numpy()).float()\n",
    "\n",
    "train_theta_loader = DataLoader(dataset=TensorDataset(train_X_tensor,train_yTh_tensor),batch_size=batchSize)\n",
    "train_phi_loader   = DataLoader(dataset=TensorDataset(train_X_tensor,train_yPh_tensor),batch_size=batchSize)\n",
    "\n",
    "test_theta_loader = DataLoader(dataset=TensorDataset(test_X_tensor,test_yTh_tensor),batch_size=batchSize)\n",
    "test_phi_loader   = DataLoader(dataset=TensorDataset(test_X_tensor,test_yPh_tensor),batch_size=batchSize)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build the model and Get the GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h2>Default Total Layer 28</h2>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def build_net(startNode = 4, maxNode=16, maxRepeat=6,NodeDropRate=4,endNode = 1):\n",
    "    Layers =[]\n",
    "    LastNode = startNode\n",
    "    currentNode = startNode\n",
    "    while currentNode <= maxNode:\n",
    "        # Layers.append([LastNode,currentNode])\n",
    "        Layers.append(nn.modules.Linear(LastNode,currentNode))\n",
    "        Layers.append(nn.modules.Sigmoid())\n",
    "        for _ in range(maxRepeat):\n",
    "            # Layers.append([currentNode,currentNode])\n",
    "            Layers.append(nn.modules.Linear(currentNode,currentNode))\n",
    "            Layers.append(nn.modules.Sigmoid())\n",
    "\n",
    "        LastNode = currentNode\n",
    "        currentNode = currentNode*NodeDropRate\n",
    "        if currentNode > maxNode:\n",
    "            currentNode = currentNode//NodeDropRate\n",
    "            break\n",
    "    while currentNode > endNode:\n",
    "        currentNode = currentNode//NodeDropRate\n",
    "        Layers.append(nn.modules.Linear(LastNode,currentNode))\n",
    "        Layers.append(nn.modules.Sigmoid())\n",
    "\n",
    "        # Layers.append([LastNode,currentNode])\n",
    "        for _ in range(maxRepeat):\n",
    "            Layers.append(nn.modules.Linear(currentNode,currentNode))\n",
    "            Layers.append(nn.modules.Sigmoid())\n",
    "            # Layers.append([currentNode,currentNode])\n",
    "        LastNode = currentNode\n",
    "\n",
    "    Layers.append(nn.modules.Linear(currentNode,currentNode))\n",
    "\n",
    "    return Layers\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<h2>Default Total Layer {}</h2>'.format(len(build_net())//2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train the model With All GPUs\n",
    "### 1. Train the $\\theta_{targ}$ dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/newdriver/Storage/HomeDir/Learning/spectrometer_nn/venv/lib/python3.9/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200, 0.010000] loss: 0.063371040\n",
      "[1,   400, 0.010000] loss: 0.000345463\n",
      "[1,   600, 0.010000] loss: 0.000421459\n",
      "[1,   800, 0.010000] loss: 0.000402794\n",
      "[1,  1000, 0.010000] loss: 0.000359194\n",
      "[1,  1200, 0.010000] loss: 0.000376992\n",
      "[1,  1400, 0.010000] loss: 0.000447341\n",
      "[1,  1600, 0.010000] loss: 0.000436900\n",
      "[1,  1800, 0.010000] loss: 0.000398659\n",
      "[1,  2000, 0.010000] loss: 0.000412482\n",
      "[1,  2200, 0.010000] loss: 0.000448166\n",
      "[1,  2400, 0.010000] loss: 0.000457179\n",
      "[1,  2600, 0.010000] loss: 0.000454177\n",
      "[1,  2800, 0.010000] loss: 0.000461210\n",
      "[1,  3000, 0.010000] loss: 0.000498984\n",
      "[1,  3200, 0.010000] loss: 0.000435775\n",
      "[1,  3400, 0.010000] loss: 0.000421482\n",
      "[1,  3600, 0.010000] loss: 0.000522570\n",
      "[1,  3800, 0.010000] loss: 0.000517138\n",
      "[1,  4000, 0.010000] loss: 0.000431429\n",
      "[1,  4200, 0.010000] loss: 0.000465388\n",
      "[1,  4400, 0.010000] loss: 0.000508599\n",
      "[1,  4600, 0.010000] loss: 0.000464756\n",
      "[1,  4800, 0.010000] loss: 0.000472855\n",
      "[1,  5000, 0.010000] loss: 0.000527627\n",
      "[1,  5200, 0.010000] loss: 0.000494194\n",
      "[1,  5400, 0.010000] loss: 0.000463967\n",
      "[1,  5600, 0.010000] loss: 0.000477815\n",
      "[1,  5800, 0.010000] loss: 0.000511866\n",
      "[1,  6000, 0.010000] loss: 0.000483769\n",
      "[1,  6200, 0.010000] loss: 0.000334524\n",
      "[1,  6400, 0.010000] loss: 0.000457842\n",
      "[1,  6600, 0.010000] loss: 0.000476454\n",
      "[1,  6800, 0.010000] loss: 0.000578192\n",
      "[1,  7000, 0.010000] loss: 0.000544398\n",
      "[1,  7200, 0.010000] loss: 0.000478718\n",
      "[1,  7400, 0.010000] loss: 0.000480358\n",
      "[1,  7600, 0.010000] loss: 0.000457864\n",
      "[1,  7800, 0.010000] loss: 0.000552025\n",
      "[1,  8000, 0.010000] loss: 0.000547517\n",
      "[1,  8200, 0.010000] loss: 0.000438830\n",
      "[1,  8400, 0.010000] loss: 0.000549122\n",
      "[1,  8600, 0.010000] loss: 0.000531377\n",
      "[1,  8800, 0.010000] loss: 0.000452302\n",
      "[1,  9000, 0.010000] loss: 0.000477364\n",
      "[1,  9200, 0.010000] loss: 0.000477601\n",
      "[1,  9400, 0.010000] loss: 0.000507928\n",
      "[1,  9600, 0.010000] loss: 0.000430704\n",
      "[1,  9800, 0.010000] loss: 0.000464114\n",
      "[1, 10000, 0.010000] loss: 0.000450323\n",
      "[1, 10200, 0.010000] loss: 0.000494184\n",
      "[1, 10400, 0.010000] loss: 0.000538287\n",
      "[1, 10600, 0.010000] loss: 0.000511450\n",
      "[1, 10800, 0.010000] loss: 0.000487755\n",
      "[1, 11000, 0.010000] loss: 0.000534947\n",
      "[1, 11200, 0.010000] loss: 0.000478832\n",
      "[1, 11400, 0.010000] loss: 0.000517928\n",
      "[1, 11600, 0.010000] loss: 0.000462963\n",
      "[1, 11800, 0.010000] loss: 0.000444738\n",
      "[1, 12000, 0.010000] loss: 0.000544229\n",
      "[1, 12200, 0.010000] loss: 0.000555672\n",
      "[1, 12400, 0.010000] loss: 0.000479019\n",
      "[1, 12600, 0.010000] loss: 0.000495198\n",
      "[1, 12800, 0.010000] loss: 0.000424905\n",
      "[1, 13000, 0.010000] loss: 0.000484488\n",
      "[1, 13200, 0.010000] loss: 0.000413870\n",
      "[1, 13400, 0.010000] loss: 0.000511833\n",
      "[1, 13600, 0.010000] loss: 0.000495012\n",
      "[1, 13800, 0.010000] loss: 0.000456213\n",
      "[1, 14000, 0.010000] loss: 0.000488178\n",
      "[1, 14200, 0.010000] loss: 0.000508771\n",
      "[1, 14400, 0.010000] loss: 0.000526461\n",
      "[1, 14600, 0.010000] loss: 0.000399301\n",
      "[1, 14800, 0.010000] loss: 0.000478532\n",
      "[1, 15000, 0.010000] loss: 0.000582655\n",
      "[1, 15200, 0.010000] loss: 0.000495261\n",
      "[1, 15400, 0.010000] loss: 0.000497955\n",
      "[1, 15600, 0.010000] loss: 0.000483487\n",
      "[1, 15800, 0.010000] loss: 0.000430509\n",
      "[1, 16000, 0.010000] loss: 0.000482256\n",
      "[1, 16200, 0.010000] loss: 0.000496771\n",
      "[1, 16400, 0.010000] loss: 0.000469051\n",
      "[1, 16600, 0.010000] loss: 0.000465288\n",
      "[1, 16800, 0.010000] loss: 0.000423246\n",
      "[1, 17000, 0.010000] loss: 0.000489185\n",
      "[1, 17200, 0.010000] loss: 0.000446475\n",
      "[1, 17400, 0.010000] loss: 0.000428035\n",
      "[1, 17600, 0.010000] loss: 0.000547061\n",
      "[1, 17800, 0.010000] loss: 0.000481956\n",
      "[1, 18000, 0.010000] loss: 0.000468295\n",
      "[1, 18200, 0.010000] loss: 0.000483105\n",
      "[1, 18400, 0.010000] loss: 0.000514382\n",
      "[1, 18600, 0.010000] loss: 0.000422346\n",
      "[1, 18800, 0.010000] loss: 0.000423477\n",
      "[1, 19000, 0.010000] loss: 0.000474533\n",
      "[1, 19200, 0.010000] loss: 0.000484623\n",
      "[1, 19400, 0.010000] loss: 0.000480369\n",
      "[1, 19600, 0.010000] loss: 0.000538515\n",
      "[1, 19800, 0.010000] loss: 0.000516649\n",
      "[1, 20000, 0.010000] loss: 0.000496303\n",
      "[1, 20200, 0.010000] loss: 0.000489605\n",
      "[1, 20400, 0.010000] loss: 0.000424713\n",
      "[1, 20600, 0.010000] loss: 0.000471812\n",
      "[1, 20800, 0.010000] loss: 0.000423710\n",
      "[1, 21000, 0.010000] loss: 0.000479188\n",
      "[1, 21200, 0.010000] loss: 0.000465048\n",
      "[1, 21400, 0.010000] loss: 0.000416971\n",
      "[1, 21600, 0.010000] loss: 0.000483156\n",
      "[1, 21800, 0.010000] loss: 0.000454561\n",
      "[1, 22000, 0.010000] loss: 0.000543597\n",
      "[1, 22200, 0.010000] loss: 0.000520774\n",
      "[1, 22400, 0.010000] loss: 0.000511906\n",
      "[1, 22600, 0.010000] loss: 0.000455028\n",
      "[1, 22800, 0.010000] loss: 0.000437689\n",
      "[1, 23000, 0.010000] loss: 0.000483190\n",
      "[1, 23200, 0.010000] loss: 0.000503529\n",
      "[1, 23400, 0.010000] loss: 0.000400549\n",
      "[1, 23600, 0.010000] loss: 0.000426013\n",
      "[1, 23800, 0.010000] loss: 0.000389807\n",
      "[1, 24000, 0.010000] loss: 0.000456995\n",
      "[1, 24200, 0.010000] loss: 0.000495700\n",
      "[1, 24400, 0.010000] loss: 0.000468829\n",
      "[1, 24600, 0.010000] loss: 0.000448676\n",
      "[1, 24800, 0.010000] loss: 0.000442637\n",
      "[1, 25000, 0.010000] loss: 0.000463371\n",
      "[1, 25200, 0.010000] loss: 0.000441235\n",
      "[1, 25400, 0.010000] loss: 0.000474895\n",
      "[1, 25600, 0.010000] loss: 0.000512397\n",
      "[1, 25800, 0.010000] loss: 0.000494389\n",
      "[1, 26000, 0.010000] loss: 0.000451467\n",
      "[1, 26200, 0.010000] loss: 0.000477023\n",
      "[1, 26400, 0.010000] loss: 0.000412569\n",
      "[1, 26600, 0.010000] loss: 0.000566124\n",
      "[1, 26800, 0.010000] loss: 0.000464107\n",
      "[1, 27000, 0.010000] loss: 0.000447980\n",
      "[1, 27200, 0.010000] loss: 0.000456641\n",
      "[1, 27400, 0.010000] loss: 0.000506378\n",
      "[1, 27600, 0.010000] loss: 0.000442029\n",
      "[1, 27800, 0.010000] loss: 0.000584185\n",
      "[1, 28000, 0.010000] loss: 0.000435522\n",
      "[1, 28200, 0.010000] loss: 0.000558528\n",
      "[1, 28400, 0.010000] loss: 0.000448945\n",
      "[1, 28600, 0.010000] loss: 0.000443368\n",
      "[1, 28800, 0.010000] loss: 0.000426723\n",
      "[1, 29000, 0.010000] loss: 0.000463577\n",
      "[1, 29200, 0.010000] loss: 0.000429526\n",
      "[1, 29400, 0.010000] loss: 0.000450523\n",
      "[1, 29600, 0.010000] loss: 0.000505627\n",
      "[1, 29800, 0.010000] loss: 0.000432290\n",
      "[1, 30000, 0.010000] loss: 0.000417174\n",
      "[1, 30200, 0.010000] loss: 0.000386701\n",
      "[1, 30400, 0.010000] loss: 0.000476992\n",
      "[1, 30600, 0.010000] loss: 0.000420754\n",
      "[1, 30800, 0.010000] loss: 0.000448024\n",
      "[1, 31000, 0.010000] loss: 0.000491241\n",
      "[1, 31200, 0.010000] loss: 0.000496683\n",
      "[1, 31400, 0.010000] loss: 0.000456249\n",
      "[1, 31600, 0.010000] loss: 0.000468056\n",
      "[1, 31800, 0.010000] loss: 0.000520889\n",
      "[1, 32000, 0.010000] loss: 0.000540969\n",
      "[1, 32200, 0.010000] loss: 0.000575558\n",
      "[1, 32400, 0.010000] loss: 0.000482469\n",
      "[1, 32600, 0.010000] loss: 0.000459168\n",
      "[1, 32800, 0.010000] loss: 0.000441765\n",
      "[1, 33000, 0.010000] loss: 0.000439375\n",
      "[1, 33200, 0.010000] loss: 0.000472624\n",
      "[1, 33400, 0.010000] loss: 0.000483864\n",
      "[1, 33600, 0.010000] loss: 0.000504176\n",
      "[1, 33800, 0.010000] loss: 0.000474231\n",
      "[1, 34000, 0.010000] loss: 0.000481094\n",
      "[1, 34200, 0.010000] loss: 0.000421937\n",
      "[1, 34400, 0.010000] loss: 0.000434916\n",
      "[1, 34600, 0.010000] loss: 0.000516476\n",
      "[1, 34800, 0.010000] loss: 0.000450032\n",
      "[1, 35000, 0.010000] loss: 0.000459221\n",
      "[1, 35200, 0.010000] loss: 0.000512384\n",
      "[1, 35400, 0.010000] loss: 0.000488317\n",
      "[1, 35600, 0.010000] loss: 0.000558464\n",
      "[1, 35800, 0.010000] loss: 0.000471502\n",
      "[1, 36000, 0.010000] loss: 0.000454837\n",
      "[1, 36200, 0.010000] loss: 0.000440546\n",
      "[1, 36400, 0.010000] loss: 0.000515564\n",
      "[1, 36600, 0.010000] loss: 0.000485021\n",
      "[1, 36800, 0.010000] loss: 0.000495447\n",
      "[1, 37000, 0.010000] loss: 0.000478649\n",
      "[1, 37200, 0.010000] loss: 0.000425549\n",
      "[1, 37400, 0.010000] loss: 0.000424457\n",
      "[1, 37600, 0.010000] loss: 0.000442235\n",
      "[1, 37800, 0.010000] loss: 0.000470038\n",
      "[1, 38000, 0.010000] loss: 0.000529889\n",
      "[1, 38200, 0.010000] loss: 0.000423802\n",
      "[1, 38400, 0.010000] loss: 0.000491352\n",
      "[1, 38600, 0.010000] loss: 0.000433381\n",
      "[1, 38800, 0.010000] loss: 0.000509448\n",
      "[1, 39000, 0.010000] loss: 0.000602786\n",
      "[1, 39200, 0.010000] loss: 0.000445793\n",
      "[1, 39400, 0.010000] loss: 0.000442811\n",
      "[1, 39600, 0.010000] loss: 0.000428052\n",
      "[1, 39800, 0.010000] loss: 0.000472237\n",
      "[1, 40000, 0.010000] loss: 0.000404507\n",
      "[1, 40200, 0.010000] loss: 0.000450649\n",
      "[1, 40400, 0.010000] loss: 0.000456969\n",
      "[1, 40600, 0.010000] loss: 0.000445474\n",
      "[1, 40800, 0.010000] loss: 0.000511130\n",
      "[1, 41000, 0.010000] loss: 0.000569551\n",
      "[1, 41200, 0.010000] loss: 0.000489930\n",
      "[1, 41400, 0.010000] loss: 0.000478290\n",
      "[1, 41600, 0.010000] loss: 0.000460086\n",
      "[1, 41800, 0.010000] loss: 0.000485372\n",
      "[1, 42000, 0.010000] loss: 0.000468278\n",
      "[1, 42200, 0.010000] loss: 0.000532272\n",
      "[1, 42400, 0.010000] loss: 0.000517865\n",
      "[1, 42600, 0.010000] loss: 0.000453239\n",
      "[1, 42800, 0.010000] loss: 0.000433839\n",
      "[1, 43000, 0.010000] loss: 0.000444124\n",
      "[1, 43200, 0.010000] loss: 0.000511262\n",
      "[1, 43400, 0.010000] loss: 0.000532315\n",
      "[1, 43600, 0.010000] loss: 0.000529855\n",
      "[1, 43800, 0.010000] loss: 0.000441719\n",
      "[1, 44000, 0.010000] loss: 0.000555317\n",
      "[1, 44200, 0.010000] loss: 0.000446213\n",
      "[1, 44400, 0.010000] loss: 0.000479075\n",
      "[1, 44600, 0.010000] loss: 0.000433371\n",
      "[1, 44800, 0.010000] loss: 0.000455904\n",
      "[1, 45000, 0.010000] loss: 0.000479253\n",
      "[1, 45200, 0.010000] loss: 0.000495713\n",
      "[1, 45400, 0.010000] loss: 0.000475790\n",
      "[1, 45600, 0.010000] loss: 0.000406002\n",
      "[1, 45800, 0.010000] loss: 0.000423016\n",
      "[1, 46000, 0.010000] loss: 0.000509058\n",
      "[1, 46200, 0.010000] loss: 0.000565753\n",
      "[1, 46400, 0.010000] loss: 0.000488438\n",
      "[1, 46600, 0.010000] loss: 0.000476726\n",
      "[1, 46800, 0.010000] loss: 0.000498061\n",
      "[1, 47000, 0.010000] loss: 0.000524370\n",
      "[1, 47200, 0.010000] loss: 0.000463964\n",
      "[1, 47400, 0.010000] loss: 0.000420391\n",
      "[1, 47600, 0.010000] loss: 0.000439717\n",
      "[1, 47800, 0.010000] loss: 0.000503350\n",
      "[1, 48000, 0.010000] loss: 0.000459157\n",
      "[1, 48200, 0.010000] loss: 0.000491268\n",
      "[1, 48400, 0.010000] loss: 0.000545976\n",
      "[1, 48600, 0.010000] loss: 0.000514207\n",
      "[1, 48800, 0.010000] loss: 0.000556883\n",
      "[1, 49000, 0.010000] loss: 0.000454699\n",
      "[1, 49200, 0.010000] loss: 0.000607158\n",
      "[1, 49400, 0.010000] loss: 0.000497077\n",
      "[1, 49600, 0.010000] loss: 0.000562024\n",
      "[1, 49800, 0.010000] loss: 0.000475814\n",
      "[1, 50000, 0.010000] loss: 0.000536351\n",
      "[1, 50200, 0.010000] loss: 0.000425582\n",
      "[1, 50400, 0.010000] loss: 0.000497535\n",
      "[1, 50600, 0.010000] loss: 0.000557334\n",
      "[1, 50800, 0.010000] loss: 0.000521341\n",
      "[1, 51000, 0.010000] loss: 0.000433904\n",
      "[1, 51200, 0.010000] loss: 0.000501735\n",
      "[1, 51400, 0.010000] loss: 0.000511622\n",
      "[1, 51600, 0.010000] loss: 0.000426339\n",
      "[1, 51800, 0.010000] loss: 0.000522854\n",
      "[1, 52000, 0.010000] loss: 0.000473427\n",
      "[1, 52200, 0.010000] loss: 0.000469433\n",
      "[1, 52400, 0.010000] loss: 0.000486512\n",
      "[1, 52600, 0.010000] loss: 0.000486505\n",
      "[1, 52800, 0.010000] loss: 0.000429515\n",
      "[1, 53000, 0.010000] loss: 0.000506127\n",
      "[1, 53200, 0.010000] loss: 0.000518395\n",
      "[1, 53400, 0.010000] loss: 0.000600814\n",
      "[1, 53600, 0.010000] loss: 0.000450315\n",
      "[1, 53800, 0.010000] loss: 0.000435670\n",
      "[1, 54000, 0.010000] loss: 0.000512101\n",
      "[1, 54200, 0.010000] loss: 0.000513737\n",
      "[1, 54400, 0.010000] loss: 0.000515873\n",
      "[1, 54600, 0.010000] loss: 0.000434748\n",
      "[1, 54800, 0.010000] loss: 0.000457194\n",
      "[1, 55000, 0.010000] loss: 0.000499266\n",
      "[1, 55200, 0.010000] loss: 0.000490424\n",
      "[1, 55400, 0.010000] loss: 0.000509489\n",
      "[1, 55600, 0.010000] loss: 0.000527818\n",
      "[1, 55800, 0.010000] loss: 0.000459492\n",
      "[1, 56000, 0.010000] loss: 0.000483783\n",
      "[1, 56200, 0.010000] loss: 0.000494686\n",
      "[1, 56400, 0.010000] loss: 0.000488997\n",
      "[1, 56600, 0.010000] loss: 0.000432574\n",
      "[1, 56800, 0.010000] loss: 0.000548257\n",
      "[1, 57000, 0.010000] loss: 0.000503405\n",
      "[1, 57200, 0.010000] loss: 0.000524610\n",
      "[1, 57400, 0.010000] loss: 0.000483476\n",
      "[1, 57600, 0.010000] loss: 0.000468242\n",
      "[1, 57800, 0.010000] loss: 0.000499945\n",
      "[1, 58000, 0.010000] loss: 0.000563103\n",
      "[1, 58200, 0.010000] loss: 0.000422503\n",
      "[1, 58400, 0.010000] loss: 0.000434953\n",
      "[1, 58600, 0.010000] loss: 0.000433651\n",
      "[1, 58800, 0.010000] loss: 0.000439938\n",
      "[1, 59000, 0.010000] loss: 0.000485575\n",
      "[1, 59200, 0.010000] loss: 0.000518993\n",
      "[1, 59400, 0.010000] loss: 0.000446985\n",
      "[1, 59600, 0.010000] loss: 0.000501725\n",
      "[1, 59800, 0.010000] loss: 0.000438802\n",
      "[1, 60000, 0.010000] loss: 0.000447664\n",
      "[1, 60200, 0.010000] loss: 0.000493719\n",
      "[1, 60400, 0.010000] loss: 0.000487481\n",
      "[1, 60600, 0.010000] loss: 0.000431243\n",
      "[1, 60800, 0.010000] loss: 0.000453546\n",
      "[1, 61000, 0.010000] loss: 0.000421240\n",
      "[1, 61200, 0.010000] loss: 0.000451921\n",
      "[1, 61400, 0.010000] loss: 0.000471778\n",
      "[1, 61600, 0.010000] loss: 0.000572886\n",
      "[1, 61800, 0.010000] loss: 0.000525079\n",
      "[1, 62000, 0.010000] loss: 0.000459485\n",
      "[1, 62200, 0.010000] loss: 0.000496578\n",
      "[1, 62400, 0.010000] loss: 0.000521306\n",
      "[1, 62600, 0.010000] loss: 0.000513040\n",
      "[1, 62800, 0.010000] loss: 0.000454170\n",
      "[1, 63000, 0.010000] loss: 0.000427977\n",
      "[1, 63200, 0.010000] loss: 0.000401484\n",
      "[1, 63400, 0.010000] loss: 0.000459583\n",
      "[1, 63600, 0.010000] loss: 0.000479377\n",
      "[1, 63800, 0.010000] loss: 0.000426520\n",
      "[1, 64000, 0.010000] loss: 0.000512381\n",
      "[1, 64200, 0.010000] loss: 0.000458694\n",
      "[1, 64400, 0.010000] loss: 0.000440078\n",
      "[1, 64600, 0.010000] loss: 0.000520146\n",
      "[1, 64800, 0.010000] loss: 0.000546368\n",
      "[1, 65000, 0.010000] loss: 0.000445874\n",
      "[1, 65200, 0.010000] loss: 0.000428263\n",
      "[1, 65400, 0.010000] loss: 0.000469199\n",
      "[1, 65600, 0.010000] loss: 0.000413373\n",
      "[1, 65800, 0.010000] loss: 0.000570781\n",
      "[1, 66000, 0.010000] loss: 0.000469419\n",
      "[1, 66200, 0.010000] loss: 0.000414811\n",
      "[1, 66400, 0.010000] loss: 0.000479340\n",
      "[1, 66600, 0.010000] loss: 0.000459536\n",
      "[1, 66800, 0.010000] loss: 0.000462792\n",
      "[1, 67000, 0.010000] loss: 0.000540342\n",
      "[1, 67200, 0.010000] loss: 0.000506243\n",
      "[1, 67400, 0.010000] loss: 0.000503379\n",
      "[1, 67600, 0.010000] loss: 0.000480115\n",
      "[1, 67800, 0.010000] loss: 0.000417518\n",
      "[1, 68000, 0.010000] loss: 0.000442008\n",
      "[1, 68200, 0.010000] loss: 0.000448521\n",
      "[1, 68400, 0.010000] loss: 0.000503139\n",
      "[1, 68600, 0.010000] loss: 0.000435242\n",
      "[1, 68800, 0.010000] loss: 0.000441174\n",
      "[1, 69000, 0.010000] loss: 0.000411012\n",
      "[1, 69200, 0.010000] loss: 0.000458200\n",
      "[1, 69400, 0.010000] loss: 0.000537388\n",
      "[1, 69600, 0.010000] loss: 0.000454779\n",
      "[1, 69800, 0.010000] loss: 0.000485202\n",
      "[1, 70000, 0.010000] loss: 0.000556961\n",
      "[1, 70200, 0.010000] loss: 0.000572812\n",
      "[1, 70400, 0.010000] loss: 0.000454682\n",
      "[1, 70600, 0.010000] loss: 0.000463691\n",
      "[1, 70800, 0.010000] loss: 0.000619608\n",
      "[1, 71000, 0.010000] loss: 0.000558180\n",
      "[1, 71200, 0.010000] loss: 0.000547387\n",
      "[1, 71400, 0.010000] loss: 0.000499580\n",
      "[1, 71600, 0.010000] loss: 0.000439435\n",
      "[1, 71800, 0.010000] loss: 0.000446078\n",
      "[1, 72000, 0.010000] loss: 0.000471190\n",
      "[1, 72200, 0.010000] loss: 0.000501132\n",
      "[1, 72400, 0.010000] loss: 0.000540358\n",
      "[1, 72600, 0.010000] loss: 0.000434086\n",
      "[1, 72800, 0.010000] loss: 0.000501897\n",
      "[1, 73000, 0.010000] loss: 0.000540080\n",
      "[1, 73200, 0.010000] loss: 0.000466615\n",
      "[1, 73400, 0.010000] loss: 0.000503819\n",
      "[1, 73600, 0.010000] loss: 0.000403824\n",
      "[1, 73800, 0.010000] loss: 0.000555278\n",
      "[1, 74000, 0.010000] loss: 0.000471809\n",
      "[1, 74200, 0.010000] loss: 0.000499944\n",
      "[1, 74400, 0.010000] loss: 0.000445680\n",
      "[1, 74600, 0.010000] loss: 0.000410019\n",
      "[1, 74800, 0.010000] loss: 0.000467113\n",
      "[1, 75000, 0.010000] loss: 0.000492219\n",
      "[1, 75200, 0.010000] loss: 0.000456615\n",
      "[1, 75400, 0.010000] loss: 0.000467054\n",
      "[1, 75600, 0.010000] loss: 0.000452090\n",
      "[1, 75800, 0.010000] loss: 0.000488782\n",
      "[1, 76000, 0.010000] loss: 0.000546663\n",
      "[1, 76200, 0.010000] loss: 0.000430691\n",
      "[1, 76400, 0.010000] loss: 0.000424247\n",
      "[1, 76600, 0.010000] loss: 0.000541575\n",
      "[1, 76800, 0.010000] loss: 0.000492129\n",
      "[1, 77000, 0.010000] loss: 0.000470227\n",
      "[1, 77200, 0.010000] loss: 0.000470289\n",
      "[1, 77400, 0.010000] loss: 0.000483409\n",
      "[1, 77600, 0.010000] loss: 0.000430014\n",
      "[1, 77800, 0.010000] loss: 0.000496142\n",
      "[1, 78000, 0.010000] loss: 0.000432072\n",
      "[1, 78200, 0.010000] loss: 0.000396994\n",
      "[1, 78400, 0.010000] loss: 0.000469674\n",
      "[1, 78600, 0.010000] loss: 0.000502707\n",
      "[1, 78800, 0.010000] loss: 0.000478642\n",
      "[1, 79000, 0.010000] loss: 0.000478002\n",
      "[1, 79200, 0.010000] loss: 0.000535972\n",
      "[1, 79400, 0.010000] loss: 0.000456553\n",
      "[1, 79600, 0.010000] loss: 0.000462524\n",
      "[1, 79800, 0.010000] loss: 0.000598739\n",
      "[1, 80000, 0.010000] loss: 0.000524641\n",
      "[1, 80200, 0.010000] loss: 0.000446711\n",
      "[1, 80400, 0.010000] loss: 0.000467715\n",
      "[1, 80600, 0.010000] loss: 0.000454911\n",
      "[1, 80800, 0.010000] loss: 0.000425206\n",
      "[1, 81000, 0.010000] loss: 0.000599547\n",
      "[1, 81200, 0.010000] loss: 0.000470438\n",
      "[1, 81400, 0.010000] loss: 0.000400615\n",
      "[1, 81600, 0.010000] loss: 0.000450277\n",
      "[1, 81800, 0.010000] loss: 0.000450003\n",
      "[1, 82000, 0.010000] loss: 0.000479794\n",
      "[1, 82200, 0.010000] loss: 0.000537503\n",
      "[1, 82400, 0.010000] loss: 0.000475121\n",
      "[1, 82600, 0.010000] loss: 0.000539110\n",
      "[1, 82800, 0.010000] loss: 0.000558980\n",
      "[1, 83000, 0.010000] loss: 0.000424291\n",
      "[1, 83200, 0.010000] loss: 0.000458302\n",
      "[1, 83400, 0.010000] loss: 0.000479968\n",
      "[1, 83600, 0.010000] loss: 0.000448288\n",
      "[1, 83800, 0.010000] loss: 0.000471057\n",
      "[1, 84000, 0.010000] loss: 0.000465530\n",
      "[1, 84200, 0.010000] loss: 0.000475013\n",
      "[1, 84400, 0.010000] loss: 0.000536264\n",
      "[1, 84600, 0.010000] loss: 0.000406654\n",
      "[1, 84800, 0.010000] loss: 0.000418658\n",
      "[1, 85000, 0.010000] loss: 0.000464922\n",
      "[1, 85200, 0.010000] loss: 0.000472923\n",
      "[1, 85400, 0.010000] loss: 0.000444533\n",
      "[1, 85600, 0.010000] loss: 0.000452412\n",
      "[1, 85800, 0.010000] loss: 0.000413913\n",
      "[1, 86000, 0.010000] loss: 0.000404115\n",
      "[1, 86200, 0.010000] loss: 0.000472815\n",
      "[1, 86400, 0.010000] loss: 0.000618477\n",
      "[1, 86600, 0.010000] loss: 0.000430293\n",
      "[1, 86800, 0.010000] loss: 0.000430343\n",
      "[1, 87000, 0.010000] loss: 0.000497472\n",
      "[1, 87200, 0.010000] loss: 0.000413215\n",
      "[1, 87400, 0.010000] loss: 0.000470624\n",
      "[1, 87600, 0.010000] loss: 0.000459467\n",
      "[1, 87800, 0.010000] loss: 0.000450762\n",
      "[1, 88000, 0.010000] loss: 0.000444176\n",
      "[1, 88200, 0.010000] loss: 0.000500252\n",
      "[1, 88400, 0.010000] loss: 0.000467477\n",
      "[1, 88600, 0.010000] loss: 0.000471966\n",
      "[1, 88800, 0.010000] loss: 0.000573092\n",
      "[1, 89000, 0.010000] loss: 0.000487968\n",
      "[1, 89200, 0.010000] loss: 0.000448920\n",
      "[1, 89400, 0.010000] loss: 0.000432471\n",
      "[1, 89600, 0.010000] loss: 0.000488796\n",
      "[1, 89800, 0.010000] loss: 0.000479055\n",
      "[1, 90000, 0.010000] loss: 0.000501077\n",
      "[1, 90200, 0.010000] loss: 0.000500782\n",
      "[1, 90400, 0.010000] loss: 0.000475765\n",
      "[1, 90600, 0.010000] loss: 0.000528589\n",
      "[1, 90800, 0.010000] loss: 0.000428320\n",
      "[1, 91000, 0.010000] loss: 0.000516334\n",
      "[1, 91200, 0.010000] loss: 0.000386962\n",
      "[1, 91400, 0.010000] loss: 0.000475585\n",
      "[1, 91600, 0.010000] loss: 0.000419012\n",
      "[1, 91800, 0.010000] loss: 0.000479942\n",
      "[1, 92000, 0.010000] loss: 0.000473723\n",
      "[1, 92200, 0.010000] loss: 0.000452989\n",
      "[1, 92400, 0.010000] loss: 0.000514182\n",
      "[1, 92600, 0.010000] loss: 0.000482285\n",
      "[1, 92800, 0.010000] loss: 0.000412113\n",
      "[1, 93000, 0.010000] loss: 0.000478299\n",
      "[1, 93200, 0.010000] loss: 0.000505707\n",
      "[1, 93400, 0.010000] loss: 0.000560863\n",
      "[1, 93600, 0.010000] loss: 0.000438143\n",
      "[1, 93800, 0.010000] loss: 0.000482124\n",
      "[1, 94000, 0.010000] loss: 0.000494293\n",
      "[1, 94200, 0.010000] loss: 0.000564985\n",
      "[1, 94400, 0.010000] loss: 0.000494827\n",
      "[1, 94600, 0.010000] loss: 0.000495344\n",
      "[1, 94800, 0.010000] loss: 0.000399814\n",
      "[1, 95000, 0.010000] loss: 0.000547382\n",
      "[1, 95200, 0.010000] loss: 0.000507517\n",
      "[1, 95400, 0.010000] loss: 0.000443635\n",
      "[1, 95600, 0.010000] loss: 0.000523017\n",
      "[1, 95800, 0.010000] loss: 0.000535763\n",
      "[1, 96000, 0.010000] loss: 0.000505942\n",
      "[1, 96200, 0.010000] loss: 0.000485795\n",
      "[1, 96400, 0.010000] loss: 0.000445068\n",
      "[1, 96600, 0.010000] loss: 0.000493933\n",
      "[1, 96800, 0.010000] loss: 0.000475302\n",
      "[1, 97000, 0.010000] loss: 0.000458167\n",
      "[1, 97200, 0.010000] loss: 0.000359315\n",
      "[1, 97400, 0.010000] loss: 0.000442746\n",
      "[1, 97600, 0.010000] loss: 0.000453794\n",
      "[1, 97800, 0.010000] loss: 0.000445347\n",
      "[1, 98000, 0.010000] loss: 0.000411427\n",
      "[1, 98200, 0.010000] loss: 0.000484032\n",
      "[1, 98400, 0.010000] loss: 0.000416025\n",
      "[1, 98600, 0.010000] loss: 0.000432666\n",
      "[1, 98800, 0.010000] loss: 0.000435246\n",
      "[1, 99000, 0.010000] loss: 0.000381889\n",
      "[1, 99200, 0.010000] loss: 0.000473474\n",
      "[1, 99400, 0.010000] loss: 0.000431547\n",
      "[1, 99600, 0.010000] loss: 0.000465530\n",
      "[1, 99800, 0.010000] loss: 0.000489799\n",
      "[1, 100000, 0.010000] loss: 0.000559573\n",
      "[1, 100200, 0.010000] loss: 0.000390373\n",
      "[1, 100400, 0.010000] loss: 0.000457958\n",
      "[1, 100600, 0.010000] loss: 0.000470374\n",
      "[1, 100800, 0.010000] loss: 0.000418152\n",
      "[1, 101000, 0.010000] loss: 0.000506092\n",
      "[1, 101200, 0.010000] loss: 0.000447895\n",
      "[1, 101400, 0.010000] loss: 0.000459349\n",
      "[1, 101600, 0.010000] loss: 0.000563265\n",
      "[1, 101800, 0.010000] loss: 0.000483063\n",
      "[1, 102000, 0.010000] loss: 0.000495625\n",
      "[1, 102200, 0.010000] loss: 0.000488561\n",
      "[1, 102400, 0.010000] loss: 0.000508991\n",
      "[1, 102600, 0.010000] loss: 0.000425594\n",
      "[1, 102800, 0.010000] loss: 0.000480314\n",
      "[1, 103000, 0.010000] loss: 0.000499917\n",
      "[1, 103200, 0.010000] loss: 0.000519405\n",
      "[1, 103400, 0.010000] loss: 0.000475988\n",
      "[1, 103600, 0.010000] loss: 0.000491690\n",
      "[1, 103800, 0.010000] loss: 0.000481531\n",
      "[1, 104000, 0.010000] loss: 0.000451577\n",
      "[1, 104200, 0.010000] loss: 0.000565514\n",
      "[1, 104400, 0.010000] loss: 0.000520087\n",
      "[1, 104600, 0.010000] loss: 0.000467039\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-30264992430e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0;31m# print statistics\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Storage/HomeDir/Learning/spectrometer_nn/venv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m                 \u001B[0minstance\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_step_count\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m                 \u001B[0mwrapped\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minstance\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0;31m# Note that the returned function here is no longer a bound method,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Storage/HomeDir/Learning/spectrometer_nn/venv/lib/python3.9/site-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     87\u001B[0m                 \u001B[0mprofile_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"Optimizer.step#{}.step\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprofile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 89\u001B[0;31m                     \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     90\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Storage/HomeDir/Learning/spectrometer_nn/venv/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Storage/HomeDir/Learning/spectrometer_nn/venv/lib/python3.9/site-packages/torch/optim/adam.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m             \u001B[0mbeta1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbeta2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgroup\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'betas'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 108\u001B[0;31m             F.adam(params_with_grad,\n\u001B[0m\u001B[1;32m    109\u001B[0m                    \u001B[0mgrads\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m                    \u001B[0mexp_avgs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Storage/HomeDir/Learning/spectrometer_nn/venv/lib/python3.9/site-packages/torch/optim/_functional.py\u001B[0m in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m         \u001B[0;31m# Decay the first and second moment running average coefficient\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 84\u001B[0;31m         \u001B[0mexp_avg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmul_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbeta1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mbeta1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     85\u001B[0m         \u001B[0mexp_avg_sq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmul_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbeta2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maddcmul_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mbeta2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mamsgrad\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "thetaOptnet = nn.Sequential(*build_net())\n",
    "thetaOptnet.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(thetaOptnet.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_theta_loader):\n",
    "        inputs, labels = data\n",
    "        # print(inputs)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = thetaOptnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d, %6f] loss: %.9f' %\n",
    "                  (epoch + 1, i + 1, optimizer.param_groups[0]['lr'],running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "    torch.save(thetaOptnet.state_dict(), \"./model/Theta_net_ep{}.pth\".format(epoch))\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"Finish Training Theta Parameters\")\n",
    "# save the training model\n",
    "theta_model_PATH = './model/Theta_net.pth'\n",
    "torch.save(thetaOptnet.state_dict(), theta_model_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Train the $\\phi_{targ}$ dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "phiOptnet = nn.Sequential(*build_net())\n",
    "phiOptnet.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(phiOptnet.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_phi_loader):\n",
    "        inputs, labels = data\n",
    "        # print(inputs)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = phiOptnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d, %6f] loss: %.9f' %\n",
    "                  (epoch + 1, i + 1, optimizer.param_groups[0]['lr'],running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "    torch.save(thetaOptnet.state_dict(), \"./model/Phi_net_ep{}.pth\".format(epoch))\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"Finish Training Theta Parameters\")\n",
    "# save the training model\n",
    "theta_model_PATH = './model/Phi_net.pth'\n",
    "torch.save(thetaOptnet.state_dict(), theta_model_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Draw the plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}